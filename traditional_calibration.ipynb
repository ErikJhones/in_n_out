{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c550b3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-11 08:45:16.625573: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-11 08:45:16.658118: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-11 08:45:16.807615: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-11 08:45:16.808336: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-11 08:45:17.413681: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from netcal.binning.BBQ import BBQ\n",
    "from netcal.binning.HistogramBinning import HistogramBinning\n",
    "from netcal.binning.IsotonicRegression import IsotonicRegression\n",
    "from netcal.scaling import TemperatureScaling\n",
    "from netcal.metrics import ECE\n",
    "from numpy import random\n",
    "random.rand(4)\n",
    "\n",
    "def traditional_calibrator(link_logits, link_labels,  link_logits_test, tipo='iso'):\n",
    "    if tipo=='iso':\n",
    "        lr = IsotonicRegression()\n",
    "        lr.fit(link_logits, link_labels)\n",
    "        lr_test_predictions = lr.transform(link_logits_test)\n",
    "    elif tipo=='temp':\n",
    "        lr = TemperatureScaling()\n",
    "        lr.fit(link_logits, link_labels)\n",
    "        lr_test_predictions = lr.transform(link_logits_test)\n",
    "    elif tipo=='bbq':\n",
    "        lr = BBQ()\n",
    "        lr.fit(link_logits, link_labels)\n",
    "        lr_test_predictions = lr.transform(link_logits_test)\n",
    "    elif tipo=='hist':\n",
    "        lr = HistogramBinning(bins=16, equal_intervals=True)\n",
    "        lr.fit(link_logits, link_labels)\n",
    "        lr_test_predictions = lr.transform(link_logits_test)\n",
    "    \n",
    "    return lr_test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e5155ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erik/.local/lib/python3.10/site-packages/torch_geometric/typing.py:25: UserWarning: An issue occurred while importing 'pyg-lib'. Disabling its usage. Stacktrace: /home/erik/.local/lib/python3.10/site-packages/libpyg.so: undefined symbol: _ZNK3c104impl13OperatorEntry24assertSignatureIsCorrectENS0_12CppSignatureEb\n",
      "  warnings.warn(f\"An issue occurred while importing 'pyg-lib'. \"\n",
      "/home/erik/.local/lib/python3.10/site-packages/torch_geometric/typing.py:70: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /home/erik/.local/lib/python3.10/site-packages/libpyg.so: undefined symbol: _ZNK3c104impl13OperatorEntry24assertSignatureIsCorrectENS0_12CppSignatureEb\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n",
      "/home/erik/.local/lib/python3.10/site-packages/torch_geometric/deprecation.py:22: UserWarning: 'train_test_split_edges' is deprecated, use 'transforms.RandomLinkSplit' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from utils import expected_calibration_error, plot_reliability_diagram, get_link_labels, accuracy\n",
    "from utils_calib import ECELoss\n",
    "from models import DeepVGAE\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from torch_geometric.datasets.planetoid import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "device_string = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "device = torch.device(device_string)\n",
    "\n",
    "seed = 42\n",
    "dataset_name = \"cora\"\n",
    "gnn = 'VGAE'\n",
    "path=\"models/\"\n",
    "\n",
    "os.makedirs(\"datasets\", exist_ok=True)\n",
    "dataset = Planetoid(\"datasets\", dataset_name, transform=T.NormalizeFeatures())\n",
    "data = dataset[0].to(device)\n",
    "all_edge_index = data.edge_index\n",
    "data = train_test_split_edges(data, 0.05, 0.1)\n",
    "\n",
    "data = data.to(device)\n",
    "\n",
    "enc_in_channels = data.x.shape[1]\n",
    "enc_hidden_channels = 32\n",
    "enc_out_channels = 16\n",
    "\n",
    "\n",
    "model = DeepVGAE(enc_in_channels, enc_hidden_channels, enc_out_channels).to(device)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "ckpt_destilado = torch.load(path + gnn + '_'+dataset_name+ '_seed_' + str(seed) + '.pth.tar', map_location=torch.device(device))\n",
    "model.load_state_dict(ckpt_destilado[\"model_state\"]) \n",
    "\n",
    "for para in model.parameters():\n",
    "    para.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdbb5da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "prefix= \"train\"\n",
    "pos_edge_index_train = data[f'{prefix}_pos_edge_index']\n",
    "if prefix == 'train':\n",
    "    neg_edge_index_train = negative_sampling(\n",
    "        edge_index=data.train_pos_edge_index, #positive edges\n",
    "        num_nodes=data.num_nodes, # number of nodes\n",
    "        num_neg_samples=data.train_pos_edge_index.size(1)) # number of neg_sample equal to number of pos_edges\n",
    "else:\n",
    "    neg_edge_index = data[f'{prefix}_neg_edge_index']\n",
    "link_logits_train = model.predict(data.x, pos_edge_index_train, neg_edge_index_train)\n",
    "link_labels_train = get_link_labels(pos_edge_index_train, neg_edge_index_train, device) # get link\n",
    "edge_index_train = torch.cat([pos_edge_index_train, neg_edge_index_train], dim=1)\n",
    "n_train = edge_index_train.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "218d890b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "prefix= \"val\"\n",
    "\n",
    "pos_edge_index_val = data[f'{prefix}_pos_edge_index']\n",
    "neg_edge_index_val = data[f'{prefix}_neg_edge_index']\n",
    "\n",
    "edge_index_val = torch.cat([pos_edge_index_val, neg_edge_index_val], dim=1)\n",
    "n_val = edge_index_val.shape[1]\n",
    "\n",
    "\n",
    "link_logits_val = model.predict(data.x, pos_edge_index_train, edge_index_val)[-n_val:]\n",
    "link_labels_val = get_link_labels(pos_edge_index_val, neg_edge_index_val, device) # get link\n",
    "\n",
    "\n",
    "prefix= \"test\"\n",
    "pos_edge_index_test = data[f'{prefix}_pos_edge_index'].to(device)\n",
    "neg_edge_index_test = data[f'{prefix}_neg_edge_index'].to(device)\n",
    "\n",
    "edge_index_test = torch.cat([pos_edge_index_test, neg_edge_index_test], dim=1)\n",
    "n_test = edge_index_test.shape[1]\n",
    "\n",
    "link_logits_test = model.predict(data.x, pos_edge_index_train, edge_index_test)[-n_test:]\n",
    "link_labels_test = get_link_labels(pos_edge_index_test, neg_edge_index_test, device) # get link\n",
    "\n",
    "link_labels_val = link_labels_val.type(torch.LongTensor)\n",
    "link_labels_test = link_labels_test.type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f959b429",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ogb.linkproppred import Evaluator\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from netcal.metrics import ECE\n",
    "import numpy as np\n",
    "\n",
    "eces_test = []\n",
    "aucs_test = []\n",
    "\n",
    "link_confidences_train = torch.cat([1-link_logits_train.unsqueeze(1).sigmoid(), link_logits_train.unsqueeze(1).sigmoid()], dim=1)\n",
    "link_confidences_val = torch.cat([1-link_logits_val.unsqueeze(1).sigmoid(), link_logits_val.unsqueeze(1).sigmoid()], dim=1)\n",
    "link_confidences_test = torch.cat([1-link_logits_test.unsqueeze(1).sigmoid(), link_logits_test.unsqueeze(1).sigmoid()], dim=1)\n",
    "\n",
    "output_test = torch.tensor(traditional_calibrator(link_confidences_train.cpu().numpy(),\n",
    "       link_labels_train.cpu().numpy(),\n",
    "       link_confidences_test.cpu().numpy(),\n",
    "        tipo='hist')).unsqueeze(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ed113b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ece: 0.06436632\n"
     ]
    }
   ],
   "source": [
    "metric = ECE(15)\n",
    "ece = metric.measure(torch.cat([1-output_test, output_test], dim=1).numpy(), link_labels_test.numpy())\n",
    "print(f'ece: {round(ece,8)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
